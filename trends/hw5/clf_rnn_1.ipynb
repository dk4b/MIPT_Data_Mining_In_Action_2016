{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for Natural Language Processing\n",
    "\n",
    "\n",
    " * Simple text representations, bag of words\n",
    " * Word embedding and... not just another word2vec this time\n",
    " * rnn for text\n",
    " * Aggregating several data sources \"the hard way\"\n",
    " * Solving ~somewhat~ real ML problem with ~almost~ end-to-end deep learning\n",
    " \n",
    "\n",
    "Special thanks to Irina Golzmann for help with technical part, task prepared by Александр Панин, jheuristic@yandex-team.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "You will require nltk v3.2 to solve this assignment\n",
    "\n",
    "__It is really important that the version is 3.2, otherwize russian tokenizer might not work__\n",
    "\n",
    "Install/update\n",
    "* `sudo pip install --upgrade nltk==3.2`\n",
    "* If you don't remember when was the last pip upgrade, `sudo pip install --upgrade pip`\n",
    "\n",
    "If for some reason you can't or won't switch to nltk v3.2, just make sure that russian words are tokenized properly with RegeExpTokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For students with low-RAM machines\n",
    " * This assignment can be accomplished with even the low-tier hardware (<= 4Gb RAM) \n",
    " * If that is the case, turn flag \"low_RAM_mode\" below to True\n",
    " * If you have around 8GB memory, it is unlikely that you will feel constrained by memory.\n",
    " * In case you are using a PC from last millenia, consider setting very_low_RAM=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = True\n",
    "very_low_RAM = False  #If you have <3GB RAM, set BOTH to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Ex-kaggle-competition on prohibited content detection\n",
    "\n",
    "There goes the description - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Download\n",
    "High-RAM mode,\n",
    " * Download avito_train.tsv from competition data files\n",
    "Low-RAM-mode,\n",
    " * Download downsampled dataset from here\n",
    "     * archive https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * raw https://yadi.sk/d/I1v7mZ6Sqw2WK (in case you feel masochistic)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# What's inside\n",
    "Different kinds of features:\n",
    "* 2 text fields - title and description\n",
    "* Special features - price, number of e-mails, phones, etc\n",
    "* Category and subcategory - unsurprisingly, categorical features\n",
    "* Attributes - more factors\n",
    "\n",
    "Only 1 binary target whether or not such advertisement contains prohibited materials\n",
    "* criminal, misleading, human reproduction-related, etc\n",
    "* diving into the data may result in prolonged sleep disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # a lot of ram\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #aroung 4GB ram\n",
    "    df = pd.read_csv(\"avito_train_1kk.tsv\",sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204949, 13) 0.228222107326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000299</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Костюм Didriksons Boardman, размер 100, краги,...</td>\n",
       "      <td>Костюм Didriksons Boardman, в отличном состоян...</td>\n",
       "      <td>{\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000309</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>1-к квартира, 44 м², 9/20 эт.</td>\n",
       "      <td>В кирпичном пан.-м доме, продается одноком.-ая...</td>\n",
       "      <td>{\"Тип объявления\":\"Продам\", \"Количество комнат...</td>\n",
       "      <td>2642020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000317</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Поездки на таможню, печать в паспорте</td>\n",
       "      <td>Поездки на таможню гражданам СНГ для пересечен...</td>\n",
       "      <td>{\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid      category                subcategory  \\\n",
       "0  10000010     Транспорт      Автомобили с пробегом   \n",
       "1  10000094   Личные вещи  Одежда, обувь, аксессуары   \n",
       "2  10000299   Личные вещи     Детская одежда и обувь   \n",
       "3  10000309  Недвижимость                   Квартиры   \n",
       "4  10000317        Услуги          Предложения услуг   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Toyota Sera, 1991   \n",
       "1                                   Костюм Steilmann   \n",
       "2  Костюм Didriksons Boardman, размер 100, краги,...   \n",
       "3                      1-к квартира, 44 м², 9/20 эт.   \n",
       "4              Поездки на таможню, печать в паспорте   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "2  Костюм Didriksons Boardman, в отличном состоян...   \n",
       "3  В кирпичном пан.-м доме, продается одноком.-ая...   \n",
       "4  Поездки на таможню гражданам СНГ для пересечен...   \n",
       "\n",
       "                                               attrs    price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...   150000        NaN   \n",
       "1  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...     1500        NaN   \n",
       "2  {\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...     3000        NaN   \n",
       "3  {\"Тип объявления\":\"Продам\", \"Количество комнат...  2642020        NaN   \n",
       "4  {\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...     1500        0.0   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           0           0         0         0.41  \n",
       "2           0           0           0         0         5.49  \n",
       "3           0           1           0         0        22.47  \n",
       "4           1           0           0         0         1.43  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.228222107326\n",
      "Count: 1204949\n"
     ]
    }
   ],
   "source": [
    "print \"Blocked ratio\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance-out the classes\n",
    "* Vast majority of data samples are non-prohibited\n",
    " * 250k banned out of 4kk\n",
    " * Let's just downsample random 250k legal samples to make further steps less computationally demanding\n",
    " * If you aim for high Kaggle score, consider a smarter approach to that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (1204949, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " (929953, 13),\n",
       " pandas.core.frame.DataFrame,\n",
       " (274996, 13),\n",
       " 274996)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_blocked_0 = df[df.is_blocked == 0]\n",
    "is_blocked_1 = df[df.is_blocked == 1]\n",
    "\n",
    "type(is_blocked_0), is_blocked_0.shape, type(is_blocked_1), is_blocked_1.shape, len(is_blocked_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (274996, 13))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_blocked_00 = is_blocked_0.sample(n=len(is_blocked_1), random_state=22 )\n",
    "\n",
    "type(is_blocked_00), is_blocked_00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (549992, 13), 0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds = is_blocked_00.append(is_blocked_1)\n",
    "\n",
    "type(df_ds), df_ds.shape, df_ds.is_blocked.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>821650</th>\n",
       "      <td>71373219</td>\n",
       "      <td>Работа</td>\n",
       "      <td>Резюме</td>\n",
       "      <td>Менеджер</td>\n",
       "      <td>Андрей Викторович ^p Менеджер. ^p Возраст: 35 ...</td>\n",
       "      <td>{\"Сфера деятельности\":\"Административная работа...</td>\n",
       "      <td>18000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          itemid category subcategory     title  \\\n",
       "821650  71373219   Работа      Резюме  Менеджер   \n",
       "\n",
       "                                              description  \\\n",
       "821650  Андрей Викторович ^p Менеджер. ^p Возраст: 35 ...   \n",
       "\n",
       "                                                    attrs  price  is_proved  \\\n",
       "821650  {\"Сфера деятельности\":\"Административная работа...  18000        NaN   \n",
       "\n",
       "        is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "821650           0           2           0         0        14.56  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1204941</th>\n",
       "      <td>99999648</td>\n",
       "      <td>Работа</td>\n",
       "      <td>Резюме</td>\n",
       "      <td>Дроп, нужна работа</td>\n",
       "      <td>Нужна работа писать на почту или смс!!! ^p Чес...</td>\n",
       "      <td>{\"Сфера деятельности\":\"Без опыта, студенты\", \"...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           itemid category subcategory               title  \\\n",
       "1204941  99999648   Работа      Резюме  Дроп, нужна работа   \n",
       "\n",
       "                                               description  \\\n",
       "1204941  Нужна работа писать на почту или смс!!! ^p Чес...   \n",
       "\n",
       "                                                     attrs  price  is_proved  \\\n",
       "1204941  {\"Сфера деятельности\":\"Без опыта, студенты\", \"...      0        0.0   \n",
       "\n",
       "         is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "1204941           1           0           0         0         3.57  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510086</th>\n",
       "      <td>48103780</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Nissan Murano, 2007</td>\n",
       "      <td>Автомобиль приобретен в России у официального ...</td>\n",
       "      <td>{\"Марка\":\"Nissan\", \"Модель\":\"Murano\", \"Год вып...</td>\n",
       "      <td>600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949749</th>\n",
       "      <td>80961225</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Элитный алкоголь, оптовые цены. В розницу</td>\n",
       "      <td>Предоставляю вашему вниманию небольшой ряд эли...</td>\n",
       "      <td>{\"Вид услуги\":\"Праздники, мероприятия\"}</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855729</th>\n",
       "      <td>73921237</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Телефоны</td>\n",
       "      <td>Новые чехлы для iPhone 4 4s</td>\n",
       "      <td>Новые чехлы для iPhone 4 4s</td>\n",
       "      <td>{\"Вид телефона\":\"Аксессуары\", \"Вид товара\":\"Че...</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048548</th>\n",
       "      <td>88339453</td>\n",
       "      <td>Хобби и отдых</td>\n",
       "      <td>Охота и рыбалка</td>\n",
       "      <td>Продам</td>\n",
       "      <td>Пистолет 79-9т 9мм. Макарыч травмотический</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874868</th>\n",
       "      <td>75340572</td>\n",
       "      <td>Работа</td>\n",
       "      <td>Вакансии</td>\n",
       "      <td>Привлечение клиентов</td>\n",
       "      <td>РАССКАЖУ КАК 250 РУБ ПРЕВРАТИТЬ В 30000 РУБ ЗА...</td>\n",
       "      <td>{\"Сфера деятельности\":\"Банки, инвестиции\", \"Гр...</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           itemid             category            subcategory  \\\n",
       "510086   48103780            Транспорт  Автомобили с пробегом   \n",
       "949749   80961225               Услуги      Предложения услуг   \n",
       "855729   73921237  Бытовая электроника               Телефоны   \n",
       "1048548  88339453        Хобби и отдых        Охота и рыбалка   \n",
       "874868   75340572               Работа               Вакансии   \n",
       "\n",
       "                                             title  \\\n",
       "510086                         Nissan Murano, 2007   \n",
       "949749   Элитный алкоголь, оптовые цены. В розницу   \n",
       "855729                 Новые чехлы для iPhone 4 4s   \n",
       "1048548                                     Продам   \n",
       "874868                        Привлечение клиентов   \n",
       "\n",
       "                                               description  \\\n",
       "510086   Автомобиль приобретен в России у официального ...   \n",
       "949749   Предоставляю вашему вниманию небольшой ряд эли...   \n",
       "855729                         Новые чехлы для iPhone 4 4s   \n",
       "1048548         Пистолет 79-9т 9мм. Макарыч травмотический   \n",
       "874868   РАССКАЖУ КАК 250 РУБ ПРЕВРАТИТЬ В 30000 РУБ ЗА...   \n",
       "\n",
       "                                                     attrs   price  is_proved  \\\n",
       "510086   {\"Марка\":\"Nissan\", \"Модель\":\"Murano\", \"Год вып...  600000        NaN   \n",
       "949749             {\"Вид услуги\":\"Праздники, мероприятия\"}    1500        0.0   \n",
       "855729   {\"Вид телефона\":\"Аксессуары\", \"Вид товара\":\"Че...     100        NaN   \n",
       "1048548                                                NaN       0        1.0   \n",
       "874868   {\"Сфера деятельности\":\"Банки, инвестиции\", \"Гр...   15000        0.0   \n",
       "\n",
       "         is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "510086            0           0           0         0         0.05  \n",
       "949749            1           0           0         0         0.11  \n",
       "855729            0           0           0         0        19.18  \n",
       "1048548           1           0           0         0         0.06  \n",
       "874868            1           0           0         1         0.74  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds = df_ds.sample(n=len(df_ds), random_state=22 )\n",
    "df_ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.5\n",
      "Count: 549992\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "#< downsample data so that both classes have approximately equal ratios>\n",
    "\n",
    "df = df_ds  #<downsampled dataset>\n",
    "\n",
    "print \"Blocked ratio:\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "very_low_RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In case your RAM-o-meter is in the red\n",
    "if very_low_RAM:\n",
    "    data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tokenizing\n",
    "\n",
    "First, we create a dictionary of all existing words.\n",
    "Assign each word a number - it's Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 s, sys: 240 ms, total: 24.2 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare tokens\n",
    "\n",
    "We are unlikely to make use of words that are only seen a few times throughout the corpora.\n",
    "\n",
    "Again, if you want to beat Kaggle competition metrics, consider doing something better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61ad64cc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_=plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "\n",
    "min_count = 55\n",
    "#tokens = <tokens from token_counts keys that had at least min_count occurences throughout the dataset>\n",
    "tokens = [token for token in token_counts if token_counts[token] >= min_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 30187\n"
     ]
    }
   ],
   "source": [
    "print \"# Tokens:\",len(token_to_id)\n",
    "if len(token_to_id) < 30000:\n",
    "    print \"Alarm! It seems like there are too few tokens. Make sure you updated NLTK and applied correct thresholds -- unless you now what you're doing, ofc\"\n",
    "if len(token_to_id) > 1000000:\n",
    "    print \"Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs\n",
    "Set a maximum length for titles and descriptions.\n",
    " * If string is longer that that limit - crop it, if less - pad with zeros.\n",
    " * Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    " * Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token,0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 536 ms, total: 31.2 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data format examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (549992, 15)\n",
      "Nissan Murano, 2007 -> [ 2764 28368 11049     0     0     0     0     0     0     0] ...\n",
      "Элитный алкоголь, оптовые цены. В розницу -> [ 2602  2167 12767 28767 27520 20192     0     0     0     0] ...\n",
      "Новые чехлы для iPhone 4 4s -> [12847 28111 28348 10276 20570 17713     0     0     0     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ As you can see, our preprocessing is somewhat crude. Let us see if that is enough for our network __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-sequences\n",
    "\n",
    "\n",
    "Some data features are not text samples. E.g. price, # urls, category, etc\n",
    "\n",
    "They require a separate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549992, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat_subcat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#categories = [A list of dictionaries {\"category\":category_name, \"subcategory\":subcategory_name} for each data sample]\n",
    "categories = [{\"category\":d_c_s[0], \"subcategory\":d_c_s[1]} for d_c_s in data_cat_subcat]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "#Non-sequences\n",
    "\n",
    "#df_non_text = df_non_text.astype('float32')\n",
    "df_non_text = np.array(df_non_text.astype('float32'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into training and test set.\n",
    "\n",
    "\n",
    "#Difficulty selector:\n",
    "#Easy: split randomly\n",
    "#Medium: select test set items that have item_ids strictly above that of training set\n",
    "#Hard: do whatever you want, but score yourself using kaggle private leaderboard\n",
    "\n",
    "#title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = <define_these_variables>\n",
    "\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr, target_ts = train_test_split(title_tokens, desc_tokens, df_non_text, target, test_size=0.1, random_state=22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data [optional]\n",
    "\n",
    "* The next tab can be used to stash all the essential data matrices and get rid of the rest of the data.\n",
    " * Highly recommended if you have less than 1.5GB RAM left\n",
    "* To do that, you need to first run it with save_prepared_data=True, then restart the notebook and only run this tab with read_prepared_data=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(title_tr), type(title_ts), type(desc_tr), type(desc_ts), type(nontext_tr), type(nontext_ts), type(target_tr), type(target_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((494992, 15),\n",
       " (55000, 15),\n",
       " (494992, 150),\n",
       " (55000, 150),\n",
       " (494992, 67),\n",
       " (55000, 67),\n",
       " (494992,),\n",
       " (55000,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tr.shape,title_ts.shape,desc_tr.shape,desc_ts.shape,nontext_tr.shape,nontext_ts.shape,target_tr.shape,target_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data (may take up to 3 minutes)\n",
      "готово\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = True #save\n",
    "read_prepared_data = False #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Saving preprocessed data (may take up to 3 minutes)\"\n",
    "    data_tuple = title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Reading saved data...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print \"done\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading saved data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = False #save\n",
    "read_prepared_data = True #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Saving preprocessed data (may take up to 3 minutes)\"\n",
    "    data_tuple = title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Reading saved data...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print \"done\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((494992, 15),\n",
       " (55000, 15),\n",
       " (494992, 150),\n",
       " (55000, 150),\n",
       " (494992, 67),\n",
       " (55000, 67),\n",
       " (494992,),\n",
       " (55000,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tr.shape,title_ts.shape,desc_tr.shape,desc_ts.shape,nontext_tr.shape,nontext_ts.shape,target_tr.shape,target_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(title_tr), type(title_ts), type(desc_tr), type(desc_ts), type(nontext_tr), type(nontext_ts), type(target_tr), type(target_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          4.40000000e+04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+02,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.50000000e+04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+02,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontext_tr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nontext_tr, nontext_ts = nontext_tr.as_matrix(), nontext_ts.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontext_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the monster\n",
    "\n",
    "Since we have several data sources, our neural network may differ from what you used to work with.\n",
    "\n",
    "* Separate input for titles: RNN\n",
    "* Separate input for description: RNN\n",
    "* Separate input for categorical features: обычные полносвязные слои или какие-нибудь трюки\n",
    " \n",
    "These three inputs must be blended somehow - concatenated or added.\n",
    "\n",
    "* Output: a simple binary classification\n",
    " * 1 sigmoidal with binary_crossentropy\n",
    " * 2 softmax with categorical_crossentropy - essentially the same as previous one\n",
    " * 1 neuron without nonlinearity (lambda x: x) +  hinge loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 inputs and a refere output\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "\n",
    "#word-wise embedding. We recommend to start from some 64 and improving after you are certain it works.\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size=  64  )\n",
    "\n",
    "#descr_nn = RNN or LSTM over embedding, maybe several ones in a stack\n",
    "\n",
    "#descr_nn = lasagne.layers.DimshuffleLayer(descr_nn, [0,2,1])\n",
    "\n",
    "descr_nn = lasagne.layers.RecurrentLayer(descr_nn, num_units= 64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Titles\n",
    "#title_nn = <Process titles somehow (title_inp)>\n",
    "\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp, input_size=len(token_to_id)+1, output_size= 64  )\n",
    "\n",
    "#title_nn = lasagne.layers.DimshuffleLayer(title_nn, [0,2,1])\n",
    "\n",
    "title_nn = lasagne.layers.RecurrentLayer(title_nn, num_units= 64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Non-sequences\n",
    "#cat_nn = <Process non-sequences(cat_inp)>\n",
    "\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 150, 64), (None, 15, 64), (None, 64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr_nn.output_shape, title_nn.output_shape, cat_nn.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descr_nn = lasagne.layers.ReshapeLayer(descr_nn, (-1, 64))\n",
    "title_nn = lasagne.layers.ReshapeLayer(title_nn, (-1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 64), (None, 64), (None, 64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr_nn.output_shape, title_nn.output_shape, cat_nn.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nn = <merge three layers into one (e.g. lasagne.layers.concat) > \n",
    "\n",
    "nn = lasagne.layers.ConcatLayer([descr_nn, title_nn, cat_nn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 192)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nn = lasagne.layers.DenseLayer(nn, 1024 )\n",
    "nn = lasagne.layers.DropoutLayer(nn, p=0.1)\n",
    "nn = lasagne.layers.DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "* The standard way:\n",
    " * prediction\n",
    " * loss\n",
    " * updates\n",
    " * training and evaluation functions\n",
    " \n",
    " \n",
    "* Hinge loss\n",
    " * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    " * delta is a tunable parameter: how far should a neuron be in the positive margin area for us to stop bothering about it\n",
    " * Function description may mention some +-1  limitations - this is not neccessary, at least as long as hinge loss has a __default__ flag `binary = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#Hinge loss\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction, target_y, delta = 1 ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "#updates = <your favorite optimizer>\n",
    "\n",
    "updates = lasagne.updates.adamax(loss, weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinitic prediction \n",
    " * In case we use stochastic elements, e.g. dropout or noize\n",
    " * Compile a separate set of functions with deterministic prediction (deterministic = True)\n",
    " * Unless you think there's no neet for dropout there ofc. Btw is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#deterministic version\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#equivalent loss function\n",
    "#det_loss = <an excercise in copy-pasting and editing>\n",
    "\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(det_prediction, target_y).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coffee-lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 s, sys: 192 ms, total: 7.19 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "* The regular way with loops over minibatches\n",
    "* Since the dataset is huge, we define epoch as some fixed amount of samples isntead of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaking guide\n",
    "\n",
    "* batch_size - how many samples are processed per function call\n",
    "  * optimization gets slower, but more stable, as you increase it.\n",
    "  * May consider increasing it halfway through training\n",
    "* minibatches_per_epoch - max amount of minibatches per epoch\n",
    "  * Does not affect training. Lesser value means more frequent and less stable printing\n",
    "  * Setting it to less than 10 is only meaningfull if you want to make sure your NN does not break down after one epoch\n",
    "* n_epochs - total amount of epochs to train for\n",
    "  * `n_epochs = 10**10` and manual interrupting is still an option\n",
    "\n",
    "\n",
    "Tips:\n",
    "\n",
    "* With small minibatches_per_epoch, network quality may jump around 0.5 for several epochs\n",
    "\n",
    "* AUC is the most stable of all three metrics\n",
    "\n",
    "* Average Precision at top 2.5% (APatK) - is the least stable. If batch_size*minibatches_per_epoch < 10k, it behaves as a uniform random variable.\n",
    "\n",
    "* Plotting metrics over training time may be a good way to analyze which architectures work better.\n",
    "\n",
    "* Once you are sure your network aint gonna crash, it's worth letting it train for a few hours of an average laptop's time to see it's true potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(desc_tr), type(title_tr), type(nontext_tr), type(target_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "minibatches_per_epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(n_epochs):\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(iterate_minibatches(desc_tr, title_tr,nontext_tr,\n",
    "                                                                        target_tr, batchsize=batch_size,\n",
    "                                                                        shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \n"
     ]
    }
   ],
   "source": [
    "print \"If you are seeing this, it's time to backup your notebook. No, really, 'tis too easy to mess up everything without noticing. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Evaluate network over the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main task\n",
    "\n",
    "* https://goo.gl/forms/eJwIeAbjxzVuo6vn1\n",
    "* Feel like Le'Cun:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (test sample size * 0.025) > 0.99\n",
    " * And perhaps even farther\n",
    "\n",
    "* Casual mode\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (test sample size * 0.025) > 0.92\n",
    "\n",
    "* Remember the training, Luke\n",
    " * Dropout, regularization\n",
    " * Mommentum, RMSprop, ada*\n",
    " * etc etc etc\n",
    " \n",
    " * If you have background in texts, there may be a way to improve tokenizer, add some lemmatization, etc etc.\n",
    " * In case you know how not to shoot yourself in the foot with RNNs, they too may be of some use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
