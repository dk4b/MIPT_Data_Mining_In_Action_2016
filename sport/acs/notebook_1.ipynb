{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Transform data actions\n",
    "#########################\n",
    "def transform(df, cross=True, scaler=None):\n",
    "    df = df.drop('id', axis=1)\n",
    "    df = cat_to_cont(df)\n",
    "\n",
    "    if cross:\n",
    "        y = df.loss.values\n",
    "        X = df.drop('loss', axis=1)\n",
    "        X_train, X_cross, y_train, y_cross = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_cross = scaler.transform(X_cross)\n",
    "\n",
    "        y_train = np.log(y_train)\n",
    "\n",
    "        return X_train, X_cross, y_train, y_cross, scaler\n",
    "    else:\n",
    "        X_test = cat_to_cont(df)\n",
    "        X_test = X_test.as_matrix()\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Convert categorical to cont features\n",
    "#######################################\n",
    "def cat_to_cont(df):\n",
    "    # Get categorical columns range\n",
    "    for i in range(1, 117):\n",
    "        col_name = \"cat{}\".format(i)\n",
    "        df[col_name] = df[col_name].astype('category')\n",
    "\n",
    "    # Convert categorical to cont\n",
    "    cat_cols = df.select_dtypes(['category']).columns\n",
    "    df[cat_cols] = df[cat_cols].apply(lambda x: x.cat.codes)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_transformed(X, est):\n",
    "    return np.exp(est.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6068           0.0535           13.09m\n",
      "         2           0.5653           0.0430           12.90m\n",
      "         3           0.5307           0.0345           12.80m\n",
      "         4           0.4999           0.0287           12.61m\n",
      "         5           0.4779           0.0226           12.45m\n",
      "         6           0.4569           0.0198           12.37m\n",
      "         7           0.4404           0.0167           12.26m\n",
      "         8           0.4257           0.0145           12.18m\n",
      "         9           0.4135           0.0122           12.10m\n",
      "        10           0.4039           0.0097           12.03m\n",
      "        11           0.3949           0.0087           11.95m\n",
      "        12           0.3873           0.0077           11.89m\n",
      "        13           0.3798           0.0071           11.82m\n",
      "        14           0.3719           0.0062           11.75m\n",
      "        15           0.3671           0.0048           11.63m\n",
      "        16           0.3616           0.0049           11.56m\n",
      "        17           0.3582           0.0042           11.44m\n",
      "        18           0.3541           0.0042           11.35m\n",
      "        19           0.3484           0.0038           11.29m\n",
      "        20           0.3453           0.0032           11.23m\n",
      "        21           0.3413           0.0031           11.15m\n",
      "        22           0.3389           0.0027           11.09m\n",
      "        23           0.3355           0.0026           11.02m\n",
      "        24           0.3343           0.0022           10.96m\n",
      "        25           0.3314           0.0022           10.89m\n",
      "        26           0.3290           0.0016           10.80m\n",
      "        27           0.3279           0.0018           10.75m\n",
      "        28           0.3249           0.0020           10.70m\n",
      "        29           0.3232           0.0016           10.63m\n",
      "        30           0.3220           0.0015           10.58m\n",
      "        31           0.3199           0.0013           10.47m\n",
      "        32           0.3179           0.0016           10.43m\n",
      "        33           0.3170           0.0012           10.36m\n",
      "        34           0.3162           0.0010           10.27m\n",
      "        35           0.3138           0.0011           10.21m\n",
      "        36           0.3120           0.0010           10.16m\n",
      "        37           0.3117           0.0007           10.05m\n",
      "        38           0.3099           0.0011           10.01m\n",
      "        39           0.3083           0.0009            9.98m\n",
      "        40           0.3078           0.0011            9.92m\n",
      "        41           0.3065           0.0007            9.87m\n",
      "        42           0.3052           0.0008            9.83m\n",
      "        43           0.3047           0.0008            9.77m\n",
      "        44           0.3039           0.0005            9.70m\n",
      "        45           0.3034           0.0005            9.61m\n",
      "        46           0.3029           0.0006            9.54m\n",
      "        47           0.3019           0.0007            9.50m\n",
      "        48           0.3014           0.0004            9.45m\n",
      "        49           0.2998           0.0008            9.39m\n",
      "        50           0.2989           0.0004            9.34m\n",
      "        51           0.2984           0.0003            9.27m\n",
      "        52           0.2982           0.0005            9.21m\n",
      "        53           0.2979           0.0005            9.16m\n",
      "        54           0.2963           0.0004            9.09m\n",
      "        55           0.2955           0.0004            9.04m\n",
      "        56           0.2960           0.0004            8.98m\n",
      "        57           0.2940           0.0004            8.93m\n",
      "        58           0.2939           0.0003            8.88m\n",
      "        59           0.2938           0.0002            8.83m\n",
      "        60           0.2946           0.0002            8.77m\n",
      "        61           0.2938           0.0002            8.70m\n",
      "        62           0.2917           0.0003            8.64m\n",
      "        63           0.2917           0.0005            8.59m\n",
      "        64           0.2920           0.0001            8.51m\n",
      "        65           0.2912           0.0003            8.47m\n",
      "        66           0.2903           0.0001            8.41m\n",
      "        67           0.2899           0.0004            8.36m\n",
      "        68           0.2903           0.0002            8.31m\n",
      "        69           0.2893           0.0002            8.28m\n",
      "        70           0.2882           0.0001            8.23m\n",
      "        71           0.2884           0.0001            8.16m\n",
      "        72           0.2876           0.0001            8.09m\n",
      "        73           0.2879           0.0001            8.01m\n",
      "        74           0.2883           0.0001            7.96m\n",
      "        75           0.2876           0.0001            7.91m\n",
      "        76           0.2875           0.0000            7.86m\n",
      "        77           0.2872           0.0002            7.81m\n",
      "        78           0.2855           0.0001            7.76m\n",
      "        79           0.2859           0.0001            7.70m\n",
      "        80           0.2857           0.0001            7.66m\n",
      "        81           0.2859           0.0001            7.61m\n",
      "        82           0.2857           0.0001            7.55m\n",
      "        83           0.2846           0.0001            7.50m\n",
      "        84           0.2849           0.0000            7.43m\n",
      "        85           0.2840           0.0001            7.39m\n",
      "        86           0.2827           0.0000            7.33m\n",
      "        87           0.2840           0.0002            7.30m\n",
      "        88           0.2830           0.0001            7.24m\n",
      "        89           0.2829           0.0001            7.19m\n",
      "        90           0.2829           0.0002            7.13m\n",
      "        91           0.2827           0.0001            7.08m\n",
      "        92           0.2813           0.0001            7.02m\n",
      "        93           0.2811           0.0001            6.98m\n",
      "        94           0.2814           0.0000            6.92m\n",
      "        95           0.2814           0.0001            6.87m\n",
      "        96           0.2805           0.0001            6.81m\n",
      "        97           0.2809           0.0001            6.77m\n",
      "        98           0.2804           0.0001            6.71m\n",
      "        99           0.2803           0.0000            6.65m\n",
      "       100           0.2797           0.0001            6.61m\n",
      "       101           0.2795           0.0001            6.57m\n",
      "       102           0.2791           0.0000            6.51m\n",
      "       103           0.2797          -0.0000            6.45m\n",
      "       104           0.2790          -0.0000            6.41m\n",
      "       105           0.2798           0.0000            6.37m\n",
      "       106           0.2788           0.0000            6.31m\n",
      "       107           0.2782           0.0001            6.26m\n",
      "       108           0.2786           0.0000            6.22m\n",
      "       109           0.2790           0.0001            6.17m\n",
      "       110           0.2782           0.0000            6.12m\n",
      "       111           0.2781           0.0000            6.06m\n",
      "       112           0.2776           0.0000            6.02m\n",
      "       113           0.2778           0.0001            5.97m\n",
      "       114           0.2773          -0.0000            5.91m\n",
      "       115           0.2770           0.0001            5.86m\n",
      "       116           0.2769           0.0001            5.81m\n",
      "       117           0.2764           0.0001            5.76m\n",
      "       118           0.2767           0.0000            5.71m\n",
      "       119           0.2762          -0.0000            5.65m\n",
      "       120           0.2763           0.0001            5.61m\n",
      "       121           0.2757           0.0001            5.56m\n",
      "       122           0.2766           0.0000            5.51m\n",
      "       123           0.2749          -0.0000            5.46m\n",
      "       124           0.2754           0.0000            5.42m\n",
      "       125           0.2759          -0.0001            5.37m\n",
      "       126           0.2745          -0.0000            5.32m\n",
      "       127           0.2756          -0.0000            5.29m\n",
      "       128           0.2739          -0.0000            5.26m\n",
      "       129           0.2750           0.0000            5.21m\n",
      "       130           0.2740           0.0001            5.17m\n",
      "       131           0.2747           0.0000            5.12m\n",
      "       132           0.2737           0.0000            5.07m\n",
      "       133           0.2741           0.0000            5.03m\n",
      "       134           0.2728           0.0000            4.98m\n",
      "       135           0.2736           0.0001            4.94m\n",
      "       136           0.2726           0.0000            4.89m\n",
      "       137           0.2724           0.0000            4.84m\n",
      "       138           0.2723           0.0000            4.80m\n",
      "       139           0.2729          -0.0000            4.75m\n",
      "       140           0.2728          -0.0000            4.70m\n",
      "       141           0.2718          -0.0000            4.65m\n",
      "       142           0.2716           0.0000            4.61m\n",
      "       143           0.2731          -0.0000            4.55m\n",
      "       144           0.2720           0.0000            4.50m\n",
      "       145           0.2718           0.0001            4.46m\n",
      "       146           0.2710           0.0000            4.41m\n",
      "       147           0.2707          -0.0000            4.37m\n",
      "       148           0.2712           0.0001            4.33m\n",
      "       149           0.2709          -0.0000            4.28m\n",
      "       150           0.2709          -0.0001            4.23m\n",
      "       151           0.2709           0.0000            4.19m\n",
      "       152           0.2703          -0.0000            4.14m\n",
      "       153           0.2699           0.0000            4.10m\n",
      "       154           0.2710          -0.0000            4.05m\n",
      "       155           0.2695           0.0001            4.02m\n",
      "       156           0.2701          -0.0001            3.97m\n",
      "       157           0.2694           0.0000            3.92m\n",
      "       158           0.2690           0.0000            3.88m\n",
      "       159           0.2694           0.0000            3.83m\n",
      "       160           0.2696           0.0000            3.79m\n",
      "       161           0.2691          -0.0000            3.74m\n",
      "       162           0.2692          -0.0000            3.69m\n",
      "       163           0.2689          -0.0000            3.65m\n",
      "       164           0.2683          -0.0000            3.60m\n",
      "       165           0.2682           0.0000            3.56m\n",
      "       166           0.2686          -0.0001            3.51m\n",
      "       167           0.2684          -0.0000            3.47m\n",
      "       168           0.2690          -0.0000            3.42m\n",
      "       169           0.2680           0.0000            3.38m\n",
      "       170           0.2682          -0.0000            3.34m\n",
      "       171           0.2682          -0.0001            3.29m\n",
      "       172           0.2678          -0.0000            3.24m\n",
      "       173           0.2675          -0.0000            3.20m\n",
      "       174           0.2674          -0.0000            3.15m\n",
      "       175           0.2677          -0.0000            3.10m\n",
      "       176           0.2674          -0.0000            3.06m\n",
      "       177           0.2674          -0.0000            3.02m\n",
      "       178           0.2667          -0.0000            2.97m\n",
      "       179           0.2667           0.0000            2.93m\n",
      "       180           0.2673          -0.0001            2.89m\n",
      "       181           0.2670          -0.0000            2.84m\n",
      "       182           0.2661           0.0000            2.80m\n",
      "       183           0.2672           0.0000            2.76m\n",
      "       184           0.2665          -0.0000            2.71m\n",
      "       185           0.2659           0.0000            2.67m\n",
      "       186           0.2662          -0.0000            2.62m\n",
      "       187           0.2668          -0.0000            2.58m\n",
      "       188           0.2658          -0.0000            2.54m\n",
      "       189           0.2659          -0.0000            2.49m\n",
      "       190           0.2656           0.0000            2.45m\n",
      "       191           0.2662          -0.0000            2.41m\n",
      "       192           0.2654          -0.0001            2.37m\n",
      "       193           0.2653          -0.0000            2.33m\n",
      "       194           0.2653          -0.0000            2.28m\n",
      "       195           0.2653          -0.0000            2.24m\n",
      "       196           0.2654          -0.0000            2.20m\n",
      "       197           0.2644          -0.0000            2.16m\n",
      "       198           0.2647          -0.0000            2.11m\n",
      "       199           0.2638          -0.0000            2.07m\n",
      "       200           0.2646          -0.0000            2.03m\n",
      "       201           0.2647           0.0000            1.99m\n",
      "       202           0.2636          -0.0000            1.95m\n",
      "       203           0.2637           0.0000            1.91m\n",
      "       204           0.2649          -0.0000            1.86m\n",
      "       205           0.2636          -0.0000            1.82m\n",
      "       206           0.2640          -0.0000            1.78m\n",
      "       207           0.2634          -0.0000            1.74m\n",
      "       208           0.2631          -0.0000            1.70m\n",
      "       209           0.2639          -0.0001            1.66m\n",
      "       210           0.2637          -0.0001            1.62m\n",
      "       211           0.2628           0.0000            1.58m\n",
      "       212           0.2628          -0.0000            1.53m\n",
      "       213           0.2632           0.0000            1.49m\n",
      "       214           0.2624          -0.0000            1.45m\n",
      "       215           0.2629          -0.0000            1.41m\n",
      "       216           0.2623           0.0000            1.37m\n",
      "       217           0.2624          -0.0000            1.33m\n",
      "       218           0.2632          -0.0000            1.29m\n",
      "       219           0.2626          -0.0000            1.25m\n",
      "       220           0.2627          -0.0000            1.21m\n",
      "       221           0.2614          -0.0001            1.17m\n",
      "       222           0.2620          -0.0001            1.13m\n",
      "       223           0.2615          -0.0001            1.08m\n",
      "       224           0.2609          -0.0001            1.04m\n",
      "       225           0.2615           0.0000            1.00m\n",
      "       226           0.2616           0.0000           57.83s\n",
      "       227           0.2613           0.0000           55.43s\n",
      "       228           0.2614          -0.0000           53.06s\n",
      "       229           0.2604          -0.0000           50.57s\n",
      "       230           0.2615          -0.0000           48.13s\n",
      "       231           0.2602          -0.0000           45.69s\n",
      "       232           0.2608           0.0000           43.26s\n",
      "       233           0.2603          -0.0000           40.82s\n",
      "       234           0.2603          -0.0000           38.42s\n",
      "       235           0.2599          -0.0000           35.98s\n",
      "       236           0.2600           0.0000           33.55s\n",
      "       237           0.2606          -0.0000           31.09s\n",
      "       238           0.2596          -0.0000           28.70s\n",
      "       239           0.2599          -0.0000           26.32s\n",
      "       240           0.2596          -0.0000           23.92s\n",
      "       241           0.2593          -0.0000           21.50s\n",
      "       242           0.2601           0.0000           19.11s\n",
      "       243           0.2598          -0.0000           16.72s\n",
      "       244           0.2588           0.0000           14.31s\n",
      "       245           0.2589          -0.0000           11.91s\n",
      "       246           0.2593          -0.0000            9.52s\n",
      "       247           0.2590          -0.0000            7.14s\n",
      "       248           0.2591          -0.0000            4.76s\n",
      "       249           0.2591          -0.0000            2.38s\n",
      "       250           0.2584          -0.0000            0.00s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cross, y_train, y_cross, scaler = transform(df)\n",
    "    \n",
    "est = GradientBoostingRegressor(n_estimators=250, learning_rate=0.1, max_depth=6,\n",
    "                                    subsample=0.9, random_state=42, \n",
    "                                    loss='ls', verbose=2).fit(X_train, y_train)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE  :   3576280.78103\n",
      "MAE  :   1142.24951823\n"
     ]
    }
   ],
   "source": [
    "    mse = mean_squared_error(y_cross, predict_transformed(X_cross, est))\n",
    "    mae = mean_absolute_error(y_cross, predict_transformed(X_cross, est))\n",
    "    \n",
    "    print(\"MSE  :   {}\".format(mse))\n",
    "    print(\"MAE  :   {}\".format(mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "id_test = df_test.id.values\n",
    "    \n",
    "X_test = transform(df_test, cross=False, scaler=scaler)\n",
    "    \n",
    "pred_test = predict_transformed(X_test, est)\n",
    "    \n",
    "submission = []\n",
    "for i in range(0, len(pred_test)):\n",
    "    submission.append([id_test[i], pred_test[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df_test.shape\n",
    "df_test.head(5)\n",
    "df.shape\n",
    "df.head(5)\n",
    "type(df)\n",
    "type(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(data=submission, columns=['id', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125546, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1478.118796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1761.608038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9209.780647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5170.003789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>833.722281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4  1478.118796\n",
       "1   6  1761.608038\n",
       "2   9  9209.780647\n",
       "3  12  5170.003789\n",
       "4  15   833.722281"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_test = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1478.118796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1761.608038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9209.780647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5170.003789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>833.722281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         loss\n",
       "0   4  1478.118796\n",
       "1   6  1761.608038\n",
       "2   9  9209.780647\n",
       "3  12  5170.003789\n",
       "4  15   833.722281"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  loss\n",
       "0   4     0\n",
       "1   6     0\n",
       "2   9     0\n",
       "3  12     0\n",
       "4  15     0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
